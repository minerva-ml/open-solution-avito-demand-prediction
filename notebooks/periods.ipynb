{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import multiprocessing as mp\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "sys.path.append('../')\n",
    "from pipelines import main\n",
    "import pipeline_config as cfg\n",
    "\n",
    "DATA_DIR = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_train = pd.read_csv(os.path.join(DATA_DIR,'train.csv'), nrows=100)\n",
    "periods_train = pd.read_csv(os.path.join(DATA_DIR,'periods_train.csv'),nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP_COLUMNS = ['activation_date','date_from','date_to']\n",
    "for col in TIMESTAMP_COLUMNS:\n",
    "    periods_train[col] = pd.to_datetime(periods_train[col], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract_period_features(df):\n",
    "    df.sort_values('activation_date', ascending=False, inplace=True)\n",
    "    df['duration'] = (df['date_to'] - df['date_from']).dt.days\n",
    "    df['activation_to_start_delta'] = (df['date_from'] - df['activation_date']).dt.days\n",
    "    df['date_to_last'] = df.shift(periods=-1)['date_to']\n",
    "    df['time_from_last_offer_ended'] = (df['date_from'] - df['date_to_last']).dt.days\n",
    "\n",
    "    cols, aggs = ['duration', 'activation_to_start_delta','time_from_last_offer_ended'], ['mean','median','max','min','std']\n",
    "    df_stat = df[cols].apply(aggs).reset_index(drop=True)\n",
    "    colnames = ['{}_{}'.format(col, agg) for agg in aggs for col in cols ]\n",
    "    df_feat = pd.DataFrame(np.ndarray.reshape(df_stat.values, (1,15)), columns=colnames)\n",
    "    df_feat['offer_count'] = df.shape[0]\n",
    "    df_feat['last_offer_activation_date'] = pd.to_datetime(df['date_to'].max(), format='%Y-%m-%d')\n",
    "    df_feat['item_id'] = df.iloc[0]['item_id']\n",
    "    df_feat.fillna(0,inplace=True)\n",
    "    return df_feat.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "feat = periods_train.groupby('item_id').apply(extract_period_features).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "groups = periods_train.groupby('item_id')\n",
    "\n",
    "def chunk_groups(groupby_object, chunk_size):\n",
    "    n_groups = groupby_object.ngroups\n",
    "    group_chunk = []\n",
    "    for i, (_, df) in enumerate(groupby_object):\n",
    "        group_chunk.append(df)\n",
    "        if (i+1)%chunk_size == 0 or i+1 == n_groups:\n",
    "            group_chunk_ = group_chunk.copy()\n",
    "            group_chunk = []\n",
    "            yield group_chunk_\n",
    "            \n",
    "def parallel_apply(groups, func, num_workers, chunk_size=100):\n",
    "    n_chunks = np.ceil(1.0*groups.ngroups/chunk_size)\n",
    "    features = []\n",
    "    for groups_chunk in tqdm(chunk_groups(groups, chunk_size), total=n_chunks):\n",
    "        with mp.pool.Pool(10) as executor:\n",
    "            features_chunk = executor.map(func, groups_chunk)\n",
    "        features.extend(features_chunk)\n",
    "    \n",
    "    features = pd.DataFrame(features)\n",
    "    return features\n",
    "\n",
    "features = parallel_apply(groups, extract_period_features, 10, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_features = main_train[['item_id','activation_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape, main_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_set = set(features['item_id'].unique())\n",
    "main_set = set(main_features['item_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(main_set & f_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_features = pd.merge(main_features, features, on='item_id')\n",
    "full_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpu py3",
   "language": "python",
   "name": "cpu_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
